---
title: Sea level anomalies
author: Ab
date: '2017-09-28'
categories: []
tags: ['sea level','ggplot','netcdf']
output:
featuredImage: "img/sat_alt.png"
---

![](/img/sat_alt.png)

Global sea level is monitored through a network of tide gages distributed along different coastlines which provide relative sea level measurements and satellite observations that provide also valuable data of global sea level.
Satellite measurements started in 1993 and different satellite have been monitoring the sea surface height (ssh). Among the products of these satellite measurements, there is the multimission altimeter satellite gridded ssh data and derived variables computed with respect to a twenty-year mean. The data are processed from all altimeter missions: Jason-3, Sentinel-3A, HY-2A, Saral/AltiKa, Cryosat-2, Jason-2, Jason-1, T/P, ENVISAT, GFO, ERS1/2. The data was previously distributed by Aviso+ and now it's made available through the Copernicus Marine Service Information [here is the link](http://marine.copernicus.eu/).

In this post, I briefly show how to download, visualise and convert/export time series for further analyses using R.

#### Data download 

There are at least 2 ways to download the data depending on the amount of data you are interested in (geographical and temporal scales).

1) Using the Copernicus Marine Service [website](http://marine.copernicus.eu/), click on Products and select Sea surface Hight from the parameter Tab (left) then scroll down to the global ocean SSH. From the new opened page, click on Download product (here you will need to create an account and log in to access the download page). 
From the download page, select the geographical area, the time range and the parameters you are interested in and click data access. However, you are only allowed to download up to 1GB of data at the same time.

2) Alternatively, if you are interested in downloading the entire records, you can access the files from ftp, here is a code to automate the downloading of the entire data-sets globally from 1993 - to present (it takes time but it does the job!)

The daily SSH data is organised in an ftp folder for each year starting from 1993 to 2017. So I use `download.file` function from `RCurl`in a for loop.

```{r, eval=F, echo=T}
# load the libraries
library(RCurl)
library(plyr)

# ftp path of the data (don't foreget to replace the username and password by your credentials)

url <- "ftp://username:password@ftp.sltac.cls.fr/Core/SEALEVEL_GLO_PHY_L4_REP_OBSERVATIONS_008_047/dataset-duacs-rep-global-merged-allsat-phy-l4-v3/"

# Destination folder
dest <- "D:/ssh/"
for (yr in 1993:2018) {
  filenames <- getURL(paste0(url, yr, "/"),
    ftp.use.epsv = FALSE, dirlistonly = TRUE, verbose = TRUE
  )
  filenames2 <- unlist(strsplit(filenames, "\r\n"))
  # Use lapply function and the outputs names are taken from the file names -characters between from 154 to 203-
lapply(
  paste0(url, u, "/", filenames2),
  function(x) download.file(x, paste0(
      "D://ssh//", substr(x, 154, 203)
    ),
    quiet = T, mode = "wb"
    )
)
}
```

#### Plot one day of SSH anomalies

To illustrate this I am using just a quick downloaded subset of ssh anomalies data along the Moroccan Atlantic ocean. The row data is in Netcdf format that we need to prepare before making the plot. 

```{r message=FALSE, warning=FALSE}
# load the necessary packages
library(ncdf4)
library(lubridate)
library(RColorBrewer)
library(tidyverse)
# set path and filename
fname <- "dataset-duacs-rep-global-merged-allsat-phy-l4_1540208137885.nc"
path <- "C:/Dropbox (AbLou)/R-projects/"
vname <- "sla"

# Read the netcdf file
ssh_nc <- nc_open(paste0(path, fname))
# Check the file
print(ssh_nc)
```

Our variable has three dimensions longitude x latitude x time. A slice of data represent one time step, so we are going to extract one slice for a given time and convert it to a date frame with long, lat and shh values so that we can plot the ssh for one time step. 


```{r echo=TRUE, message=FALSE, warning=TRUE}
# Long and lat
lon <- ncvar_get(ssh_nc, "longitude") - 360
nlon <- dim(lon)
lat <- ncvar_get(ssh_nc, "latitude")
nlat <- dim(lat)
# get time
time <- ncvar_get(ssh_nc, "time")
ntime <- dim(time)
head(time)
# the time step represented by time-since units, so we need to conevrt it to readable units
start_date <- ymd_hms("1950-01-01 00:00:00", tz = "UTC")
time2 <- days(time) + start_date
# get the ssh variable data
ssh <- ncvar_get(ssh_nc, vname)
# get ssh for the time step 1 which corresponds to 1993-01-01
s <- 1
ssh_slice <- ssh[, , s]
# check the dimension
dim(ssh_slice)
# Now you can plot a quick map if you want
image(lon, lat, ssh_slice, col = brewer.pal(10, "RdBu"))
# Create a dataframe for this signle time step
ssh_vec <- data_frame(ssh = as.vector(ssh_slice))
coord_df <- expand.grid(lon = lon, lat = lat)
ssh_df <- bind_cols(coord_df, ssh_vec)
```

We can put these last lines of code in a for loop to save each separate time step in a separate dataframe if needed.
```{r, eval=F, echo=T}
slices <- 1:ntime
for (s in slices) {
  ssh_slice <- ssh[, , s] # s=1
  # Creat a dataframe 
  ssh_vec <- data_frame(ssh = as.vector(ssh_slice))
  ssh_df <- bind_cols(coord_df, ssh_vec)
  write_delim(ssh_df, paste0(time2[s], ".txt"))
```

#### Plot the ssh on a map
#### Using leaflet 

```{r echo=TRUE, message=FALSE, warning=TRUE}
library(raster)
library(leaflet)
# convert th DF to ratser
r <- rasterFromXYZ(ssh_df, crs = CRS("+init=EPSG:4326"))
# colors 
colrs <- colorRamps::matlab.like2(10)
pal <- colorNumeric(colrs, values(r), na.color = "transparent")
# the map
leaflet() %>%
  addTiles() %>%
  addRasterImage(r, colors = pal, opacity = 0.8) %>%
  addLegend(pal = pal, values = values(r), title = "ssh")
```
 
#### Using ggplot

```{r echo=TRUE, message=FALSE, warning=TRUE}
pal2 <- colorRamps::matlab.like2(10)

ggplot() +
  theme_bw() +
  geom_tile(data = ssh_df, aes(x = lon, y = lat, fill = ssh)) +
  borders("world", fill = "grey50",colour = "grey50") +
  scale_fill_gradientn(
    colours = pal2, limits = c(-0.24, 0.2), name = "ssh",
    na.value = "white", guide = guide_colorbar(barheight = 15)
  ) +
  scale_x_continuous(limits = c(-30, -5), expand = c(0, 0)) +
  scale_y_continuous(limits = c(20, 36), expand = c(0, 0))
```


